#!/usr/bin/python3
# -*- coding: utf-8 -*-

"""
Monad RPC ä¼˜åŒ–å™¨
åŸºäºçœŸå®æµ‹è¯•ç»“æœçš„RPCè°ƒç”¨ä¼˜åŒ–å’Œé™æµå¤„ç†
"""

import asyncio
import logging
import time
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock, Semaphore
from typing import Dict, List, Optional, Any, Tuple
from functools import lru_cache
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from dataclasses import dataclass
from enum import Enum

class RPCErrorType(Enum):
    """RPCé”™è¯¯ç±»å‹"""
    RATE_LIMIT = "rate_limit"
    TIMEOUT = "timeout"
    CONNECTION = "connection"
    INVALID_RESPONSE = "invalid_response"
    UNKNOWN = "unknown"

@dataclass
class RPCRequest:
    """RPCè¯·æ±‚æ•°æ®ç»“æ„"""
    method: str
    params: List[Any]
    id: int
    created_at: float = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = time.time()
    
    def to_json(self) -> dict:
        return {
            "jsonrpc": "2.0",
            "method": self.method,
            "params": self.params,
            "id": self.id
        }

@dataclass
class RPCResponse:
    """RPCå“åº”æ•°æ®ç»“æ„"""
    success: bool
    result: Any = None
    error: Any = None
    latency: float = 0
    retry_count: int = 0

class MonadRPCOptimizer:
    """Monad RPCä¼˜åŒ–å™¨ - åŸºäºçœŸå®æµ‹è¯•ç»“æœä¼˜åŒ–"""
    
    def __init__(self, rpc_url: str, logger: logging.Logger = None):
        self.rpc_url = rpc_url
        self.logger = logger or logging.getLogger(__name__)
        
        # åŸºäºæµ‹è¯•ç»“æœçš„é…ç½®
        self.config = {
            'max_concurrent': 8,        # æœ€å¤§å¹¶å‘æ•°ï¼ˆæµ‹è¯•éªŒè¯çš„å®‰å…¨å€¼ï¼‰
            'batch_size': 100,          # æ‰¹é‡è¯·æ±‚å¤§å°ä¸Šé™
            'timeout': 45,              # è¯·æ±‚è¶…æ—¶æ—¶é—´
            'retry_attempts': 5,        # é‡è¯•æ¬¡æ•°
            'base_delay': 0.15,         # åŸºç¡€å»¶è¿Ÿ150ms
            'rate_limit_delay': 10,     # é‡åˆ°429æ—¶çš„å»¶è¿Ÿ
            'max_retry_delay': 30,      # æœ€å¤§é‡è¯•å»¶è¿Ÿ
            'circuit_breaker_threshold': 10,  # ç†”æ–­å™¨é˜ˆå€¼
        }
        
        # è¿è¡Œæ—¶çŠ¶æ€
        self.semaphore = Semaphore(self.config['max_concurrent'])
        self.session = self._create_session()
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'rate_limited_requests': 0,
            'total_latency': 0,
            'circuit_breaker_trips': 0
        }
        
        # ç†”æ–­å™¨çŠ¶æ€
        self.circuit_breaker = {
            'is_open': False,
            'failure_count': 0,
            'last_failure_time': 0,
            'reset_timeout': 60  # 1åˆ†é’Ÿåå°è¯•é‡ç½®
        }
        
        # ç¼“å­˜
        self.cache: Dict[str, Any] = {}
        self.cache_lock = Lock()
        
        self.logger.info(f"ğŸš€ Monad RPCä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œæœ€å¤§å¹¶å‘: {self.config['max_concurrent']}")
    
    def _create_session(self) -> requests.Session:
        """åˆ›å»ºä¼˜åŒ–çš„HTTPä¼šè¯"""
        session = requests.Session()
        
        # é…ç½®é‡è¯•ç­–ç•¥ - ä¸“é—¨é’ˆå¯¹Monadçš„é—®é¢˜
        retry_strategy = Retry(
            total=self.config['retry_attempts'],
            backoff_factor=2,  # æŒ‡æ•°é€€é¿
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["POST"],
            raise_on_status=False
        )
        
        # é…ç½®è¿æ¥æ± 
        adapter = HTTPAdapter(
            pool_connections=self.config['max_concurrent'],
            pool_maxsize=self.config['max_concurrent'] * 2,
            max_retries=retry_strategy
        )
        
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        # è®¾ç½®é»˜è®¤è¯·æ±‚å¤´
        session.headers.update({
            'Content-Type': 'application/json',
            'User-Agent': 'Hemera-Indexer-Monad-Optimized/1.0'
        })
        
        return session
    
    def _check_circuit_breaker(self) -> bool:
        """æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€"""
        if not self.circuit_breaker['is_open']:
            return True
        
        # æ£€æŸ¥æ˜¯å¦å¯ä»¥é‡ç½®ç†”æ–­å™¨
        if (time.time() - self.circuit_breaker['last_failure_time'] > 
            self.circuit_breaker['reset_timeout']):
            self.circuit_breaker['is_open'] = False
            self.circuit_breaker['failure_count'] = 0
            self.logger.info("ğŸ”„ ç†”æ–­å™¨é‡ç½®")
            return True
        
        return False
    
    def _update_circuit_breaker(self, success: bool):
        """æ›´æ–°ç†”æ–­å™¨çŠ¶æ€"""
        if success:
            self.circuit_breaker['failure_count'] = 0
            if self.circuit_breaker['is_open']:
                self.circuit_breaker['is_open'] = False
                self.logger.info("âœ… ç†”æ–­å™¨å…³é—­")
        else:
            self.circuit_breaker['failure_count'] += 1
            if (self.circuit_breaker['failure_count'] >= 
                self.config['circuit_breaker_threshold']):
                self.circuit_breaker['is_open'] = True
                self.circuit_breaker['last_failure_time'] = time.time()
                self.stats['circuit_breaker_trips'] += 1
                self.logger.warning(f"âš ï¸ ç†”æ–­å™¨å¼€å¯ï¼Œè¿ç»­å¤±è´¥: {self.circuit_breaker['failure_count']}")
    
    def _generate_cache_key(self, request: RPCRequest) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"{request.method}:{json.dumps(request.params, sort_keys=True)}"
    
    def _get_from_cache(self, request: RPCRequest) -> Optional[Any]:
        """ä»ç¼“å­˜è·å–ç»“æœ"""
        cache_key = self._generate_cache_key(request)
        with self.cache_lock:
            return self.cache.get(cache_key)
    
    def _set_cache(self, request: RPCRequest, result: Any, ttl: int = 300):
        """è®¾ç½®ç¼“å­˜ï¼ˆTTL=5åˆ†é’Ÿï¼‰"""
        cache_key = self._generate_cache_key(request)
        with self.cache_lock:
            self.cache[cache_key] = {
                'result': result,
                'expires_at': time.time() + ttl
            }
    
    def _cleanup_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        current_time = time.time()
        with self.cache_lock:
            expired_keys = [
                key for key, value in self.cache.items()
                if value['expires_at'] < current_time
            ]
            for key in expired_keys:
                del self.cache[key]
    
    def _classify_error(self, response: requests.Response, exception: Exception = None) -> RPCErrorType:
        """åˆ†ç±»é”™è¯¯ç±»å‹"""
        if exception:
            if isinstance(exception, requests.Timeout):
                return RPCErrorType.TIMEOUT
            elif isinstance(exception, requests.ConnectionError):
                return RPCErrorType.CONNECTION
            else:
                return RPCErrorType.UNKNOWN
        
        if response.status_code == 429:
            return RPCErrorType.RATE_LIMIT
        elif response.status_code >= 500:
            return RPCErrorType.CONNECTION
        else:
            return RPCErrorType.INVALID_RESPONSE
    
    async def _make_single_request(self, request: RPCRequest) -> RPCResponse:
        """å‘é€å•ä¸ªRPCè¯·æ±‚"""
        # æ£€æŸ¥ç†”æ–­å™¨
        if not self._check_circuit_breaker():
            return RPCResponse(
                success=False,
                error="Circuit breaker is open",
                latency=0
            )
        
        # æ£€æŸ¥ç¼“å­˜
        cached_result = self._get_from_cache(request)
        if cached_result:
            return RPCResponse(
                success=True,
                result=cached_result['result'],
                latency=0
            )
        
        # è·å–ä¿¡å·é‡
        await asyncio.sleep(0)  # è®©å‡ºæ§åˆ¶æƒ
        self.semaphore.acquire()
        
        try:
            # åº”ç”¨åŸºç¡€å»¶è¿Ÿ
            if self.config['base_delay'] > 0:
                await asyncio.sleep(self.config['base_delay'])
            
            start_time = time.time()
            
            # å‘é€è¯·æ±‚
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.session.post(
                    self.rpc_url,
                    json=request.to_json(),
                    timeout=self.config['timeout']
                )
            )
            
            latency = time.time() - start_time
            self.stats['total_requests'] += 1
            self.stats['total_latency'] += latency
            
            # å¤„ç†å“åº”
            if response.status_code == 200:
                try:
                    json_response = response.json()
                    if 'result' in json_response:
                        # æˆåŠŸå“åº”
                        self.stats['successful_requests'] += 1
                        self._update_circuit_breaker(True)
                        
                        # ç¼“å­˜ç»“æœ
                        self._set_cache(request, json_response['result'])
                        
                        return RPCResponse(
                            success=True,
                            result=json_response['result'],
                            latency=latency
                        )
                    else:
                        # RPCé”™è¯¯
                        self.stats['failed_requests'] += 1
                        self._update_circuit_breaker(False)
                        return RPCResponse(
                            success=False,
                            error=json_response.get('error', 'Unknown RPC error'),
                            latency=latency
                        )
                except json.JSONDecodeError:
                    self.stats['failed_requests'] += 1
                    self._update_circuit_breaker(False)
                    return RPCResponse(
                        success=False,
                        error="Invalid JSON response",
                        latency=latency
                    )
            else:
                # HTTPé”™è¯¯
                error_type = self._classify_error(response)
                if error_type == RPCErrorType.RATE_LIMIT:
                    self.stats['rate_limited_requests'] += 1
                    # é‡åˆ°429æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
                    await asyncio.sleep(self.config['rate_limit_delay'])
                
                self.stats['failed_requests'] += 1
                self._update_circuit_breaker(False)
                return RPCResponse(
                    success=False,
                    error=f"HTTP {response.status_code}: {response.text}",
                    latency=latency
                )
                
        except Exception as e:
            self.stats['failed_requests'] += 1
            self._update_circuit_breaker(False)
            latency = time.time() - start_time
            return RPCResponse(
                success=False,
                error=str(e),
                latency=latency
            )
        finally:
            self.semaphore.release()
    
    async def batch_request(self, requests_list: List[RPCRequest]) -> List[RPCResponse]:
        """æ‰¹é‡å‘é€RPCè¯·æ±‚"""
        if not requests_list:
            return []
        
        self.logger.debug(f"ğŸ“¦ æ‰¹é‡å¤„ç† {len(requests_list)} ä¸ªè¯·æ±‚")
        
        # åˆ†æ‰¹å¤„ç†ï¼ˆåŸºäºæµ‹è¯•ç»“æœçš„æ‰¹é‡å¤§å°ï¼‰
        results = []
        for i in range(0, len(requests_list), self.config['batch_size']):
            batch = requests_list[i:i + self.config['batch_size']]
            
            # å¹¶å‘å‘é€æ‰¹æ¬¡å†…çš„è¯·æ±‚
            tasks = [self._make_single_request(req) for req in batch]
            batch_results = await asyncio.gather(*tasks)
            results.extend(batch_results)
            
            # æ‰¹æ¬¡é—´çŸ­æš‚å»¶è¿Ÿ
            if i + self.config['batch_size'] < len(requests_list):
                await asyncio.sleep(0.1)
        
        # å®šæœŸæ¸…ç†ç¼“å­˜
        if self.stats['total_requests'] % 1000 == 0:
            self._cleanup_cache()
        
        return results
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        total_requests = self.stats['total_requests']
        if total_requests == 0:
            return self.stats.copy()
        
        stats = self.stats.copy()
        stats['success_rate'] = self.stats['successful_requests'] / total_requests
        stats['error_rate'] = self.stats['failed_requests'] / total_requests
        stats['avg_latency'] = self.stats['total_latency'] / total_requests
        stats['cache_size'] = len(self.cache)
        
        return stats
    
    def log_stats(self):
        """è®°å½•æ€§èƒ½ç»Ÿè®¡"""
        stats = self.get_stats()
        self.logger.info(
            f"ğŸ“Š RPCç»Ÿè®¡ - "
            f"æ€»è¯·æ±‚: {stats['total_requests']}, "
            f"æˆåŠŸç‡: {stats.get('success_rate', 0):.2%}, "
            f"å¹³å‡å»¶è¿Ÿ: {stats.get('avg_latency', 0):.3f}s, "
            f"ç¼“å­˜å¤§å°: {stats['cache_size']}, "
            f"é™æµæ¬¡æ•°: {stats['rate_limited_requests']}"
        )

# ä¾¿æ·å‡½æ•°
async def optimized_rpc_call(rpc_url: str, method: str, params: List[Any], 
                           request_id: int = 1) -> RPCResponse:
    """ä¼˜åŒ–çš„å•æ¬¡RPCè°ƒç”¨"""
    optimizer = MonadRPCOptimizer(rpc_url)
    request = RPCRequest(method=method, params=params, id=request_id)
    return await optimizer._make_single_request(request)

async def optimized_batch_rpc_call(rpc_url: str, requests_data: List[Tuple[str, List[Any]]], 
                                 logger: logging.Logger = None) -> List[RPCResponse]:
    """ä¼˜åŒ–çš„æ‰¹é‡RPCè°ƒç”¨"""
    optimizer = MonadRPCOptimizer(rpc_url, logger)
    requests = [
        RPCRequest(method=method, params=params, id=i)
        for i, (method, params) in enumerate(requests_data)
    ]
    return await optimizer.batch_request(requests)